{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   <center>Machine Learning Engineer Nanodegree</center>\n",
    "##   <center>Project: Dogs vs. Cats Redux: Kernels Edition</center>\n",
    "<center>\n",
    "Author: Kyle Chen<br>\n",
    "Date: 20180506<br>\n",
    "Version: 20180506v1\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "###   写在前面\n",
    "-   这次的毕业项目选做猫狗, 一方面是因为资料比较多, 资源比较丰富. 另外一方面, 图形识别也是当下的一大热点. 虽然毕业后可能会继续从事传统机器学习方面的研究, 但是能够有这段经历还是很不错的, 也能丰富自己的简历与深度学习的知识.\n",
    "-   在这个项目中, 将通过评估几种模型与不同程度的调优, 来不断优化我们的模型框架, 以达到最终的top 10%标准.\n",
    "\n",
    "###   准备数据\n",
    "-   本文中的DataSet是已经从kaggle上拖取到本地, 并放入当前工作目录中, 但是由于Github的大小限制, 如果你想要执行并研究其中的一些代码, 请自行准备好数据集, 并存放到./DataSet目录下. kaggle传送门 <a href='https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data'>dogs-vs-cats-redux-kernels-edition/data</a>.\n",
    "-   或者你可以直接运行下框的代码创建目录结构与拖取数据."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果你已经拖取了数据, 请勿执行此代码框中的代码\n",
    "!mkdir DataSet\n",
    "!wget -c \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/5441/train.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1525872567&Signature=Vp1XJm2t%2FeDE9TqhWRHhhDuCD7GmOw4LhuU9cVU%2FNKbur08UKSw8UkDRm%2B6quFq0NL41vn%2BA45YkXvwlmiyM%2Br51%2BvXpWUHtYi3XAMwxjEVn7HI7dwyEP2tSO1H9SS%2Bi5YM8e94zNQ5mrpUypxL52HDBH0BVJBGs40RFR7uAiSeLizUNwArPl5zyP11EkOPrcFC2umd8e5BmfxpfRWUNTwr4%2FpfN6AAu%2BOsPU3QakCnzqxYQ1idOsQ4AO4AecseLYtEdeXJaov0lwaUVh9BIRMZibW4Sylh9RW0QmTspNbeCdZ%2BiTzMMfHxII5DhuXznZcpHOLRIG7%2F8XqOULoMzAA%3D%3D\" -O DataSet/train.zip\n",
    "!wget -c \"https://storage.googleapis.com/kaggle-competitions-data/kaggle/5441/test.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1525872601&Signature=aHXH%2B1qiQOk5ny9b3YrivSZQB23neGcHxVubwp6olX8SPz6V5wfkqpbs2ncy%2B%2BLozRBLx%2BG86KdjqsuGuo%2FbYYjMwwh%2F1784dKFaNlFxBR3x8jIn6ji221MWwCkX9Cij20xC9ECpaXWBap8jYypRlAp%2Ff8AlTJF1zY8xQ84su8Gs2y8tDVs9Gt0OuiKu4dNJ017ZPjclPYNjm2%2BCG1GcpgCmZy6qkqvW%2FsuMPr%2BLcGFB1X0xrqYLxmX1JJGlikoZ%2FjQiJ5ZYjIhnLm05BhWdegChS24hnDyF4Mo4DoI9r9NBpRIPqF3kW%2BSZ0ci%2FRgutEvqr7OXcuRpOIR4pPYVZdw%3D%3D\" -O DataSet/test.zip\n",
    "!unzip test/train.zip -d DataSet/\n",
    "!unzip test/test.zip -d DataSet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   关于DataSet\n",
    "-   先了解下数据集的组成."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 109136\r\n",
      "drwxr-xr-x      7 Kyle  staff   224B May  7 21:33 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x     10 Kyle  staff   320B May  7 21:32 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--      1 Kyle  staff   111K May  7 15:08 sample_submission.csv\r\n",
      "drwxr-xr-x  12502 Kyle  staff   391K May  7 15:08 \u001b[1m\u001b[36mtest\u001b[m\u001b[m\r\n",
      "-rw-r--r--@     1 Kyle  staff   3.7M May  7 21:33 test.zip\r\n",
      "drwxr-xr-x  25002 Kyle  staff   781K May  7 15:08 \u001b[1m\u001b[36mtrain\u001b[m\u001b[m\r\n",
      "-rw-r--r--@     1 Kyle  staff    49M May  7 21:33 train.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ahl DataSet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   test目录下存放的是kaggle准备好的测试集.\n",
    "-   train目录下存放的是训练集, 当然, 还需要将其细分为训练集与验证集两个部分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1217008\r\n",
      "drwxr-xr-x  25002 Kyle  staff   781K May  7 15:08 .\r\n",
      "drwxr-xr-x      7 Kyle  staff   224B May  7 21:33 ..\r\n",
      "-rw-r--r--      1 Kyle  staff    12K May  7 15:08 cat.0.jpg\r\n",
      "-rw-r--r--      1 Kyle  staff    16K May  7 15:08 cat.1.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ahl DataSet/train/ | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   发现数据集命名是有规则的, 遵循label.n.jpg的原则."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats |    12500\n",
      "dogs |    12500\n"
     ]
    }
   ],
   "source": [
    "!echo \"cats | $(find DataSet/train/ -name 'cat*' | wc -l)\"\n",
    "!echo \"dogs | $(find DataSet/train/ -name 'dog*' | wc -l)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   发现cats/dogs样本类型分布均匀."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入我们后面需要用到的库\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Initial Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial global variables\n",
    "TRAIN_DIR = 'DataSet/train'\n",
    "TEST_DIR = 'DataSet/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from TRAIN_DIR\n",
    "def load_data():\n",
    "    img_list = os.listdir(TRAIN_DIR)\n",
    "    nums = len(img_list)\n",
    "    data = np.empty((nums, 224, 224, 3), dtype=\"float32\")\n",
    "    label = np.empty((nums, ))\n",
    "    \n",
    "    i = 0\n",
    "    while i < nums:\n",
    "        img = img_list[i]\n",
    "        imgObj = Image.open(\"{}/{}\".format(TRAIN_DIR, img))\n",
    "        arr = np.asarray(imgObj, dtype=\"float32\")\n",
    "        arr.resize((224, 224, 3))\n",
    "        data[i, :, :, :] = arr\n",
    "        \n",
    "        if re.match(r'^cat\\.', img) != None:\n",
    "            label[i] = 0\n",
    "            \n",
    "        elif re.match(r'^dog\\.', img) != None:\n",
    "            label[i] = 1            \n",
    "        i += 1\n",
    "    return(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run load data\n",
    "data, label = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   CNN模型框架设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 223, 223, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 111, 111, 133)     2261      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 110, 110, 32)      17056     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 55, 55, 133)       4389      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 54, 54, 64)        34112     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 58,155\n",
      "Trainable params: 58,123\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `GlobalAveragePooling2D` call to the Keras 2 API: `GlobalAveragePooling2D(data_format=None)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "cnn_model = Sequential()\n",
    "shape_input = (len(data[0]), len(data[0][0]), len(data[0][0][0]))\n",
    "cnn_model.add(Conv2D(filters=16, kernel_size=2, input_shape=shape_input))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(MaxPooling2D(pool_size=2, padding='valid'))\n",
    "cnn_model.add(Dense(133, activation='relu'))\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=2))\n",
    "cnn_model.add(MaxPooling2D(pool_size=2, padding='valid'))\n",
    "cnn_model.add(Dense(133, activation='relu'))\n",
    "cnn_model.add(Conv2D(filters=64, kernel_size=2))\n",
    "cnn_model.add(MaxPooling2D(pool_size=2, padding='valid'))\n",
    "cnn_model.add(GlobalAveragePooling2D(dim_ordering='default'))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 编译模型\n",
    "cnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   训练CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/5\n",
      "15580/17500 [=========================>....] - ETA: 2:11 - loss: 0.7010 - acc: 0.5418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-36-26d49c01d04f>\", line 7, in <module>\n",
      "    callbacks=[checkpointer], verbose=1)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 963, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1705, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1235, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2478, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 778, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 982, in _run\n",
      "    feed_dict_string, options, run_metadata)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1032, in _do_run\n",
      "    target_list, options, run_metadata)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1039, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1021, in _run_fn\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/anaconda3/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 20\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.cnn.hdf5', \n",
    "                                   verbose=1, save_best_only=True)\n",
    "cnn_model.fit(data, label, validation_split = 0.3,\n",
    "                epochs = epochs, batch_size = batch_size, shuffle = True,\n",
    "                callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predictions = cnn_model.predict(data, batch_size = 32)\n",
    "cnn_predictions = [np.argmax(pre) for pre in cnn_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "# 报告测试准确率\n",
    "test_accuracy = 100*np.sum(np.array(cnn_predictions)==np.argmax(label))/len(cnn_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
